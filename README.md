# TCC-My-Brain-Computer-Interface

### 1. PROPOSTA

Neste presente Trabalho de Conclusão de Curso, primeiramente é desenvolvido e proposto o projeto de um circuito de Eletroencefalograma (EEG) de baixo custo. Em seguida, sinais cerebrais são registrados e analisados, submetendo-os às principais técnicas de pré-processamento, extração de características e classificação de sinais, existentes na área. Essas técnicas são utilizadas como ferramentas a fim de contornar as dificuldades de se lidar com os sinais de baixa intensidade e com muito ruído. Esse trabalho tem como o objetivo abordar essas principais técnicas trazendo uma interação entre diferentes metodologias, aplicadas a uma ICC de baixo custo e de apenas um canal, explorando os resultados de performance em modo offline.

### 2. METODOLOGIA

 #### A. Design de um Circuito EEG de Baixo Custo
  Neste presente projeto, devido a intenção de desenvolver uma proposta simples e de fácil desenvolvimento e reprodução quando comparado com outros modelos, foi escolhida a implementação de um circuito de EEG de apenas um canal, com a configuração bipolar, usando eletrodos passivos. Os dois terminais do amplificador de instrumentação são utilizados para aquisição de sinal, em conjunto com os eletrodos, e mais um eletrodo é utilizado para ser a referência da terra virtual do sistema.<br>
![circ logo](/pic/circ.PNG)
  O circuito apresenta três estágios de amplificação e quatro estágios de filtragem. No primeiro estágio de amplificação é empregado o amplificador de instrumentação AD620AN, que irá mensurar a diferença de potencial entre dois eletrodos, e por ter a característica de alta rejeição de modo em comum (CMRR), apresentará uma melhor rejeição do ruído da linha de 60 Hz. Entre suas portas 1 e 8 é inserido um resistor de 330Ω, que lhe proporciona um ganho de 150x.<br>
Após o primeiro estágio de amplificação se encontra um capacitor de acoplamento de 1uF, responsável por bloquear sinais de corrente contínua, seguido de um filtro passa altas ativo de 0,1 Hz com um ganho variável de 1 à 4x, que tem a função de filtrar alguns componentes de baixa frequência que estão incorporados no sinal EEG, devido à alguns artefatos. Para o amplificador ativo é utilizado o amplificador operacional CA3140.<br>
  No próximo estágio se encontra um filtro passa-baixa RC passivo de 159 Hz. Esta frequência de corte foi escolhida para preservar componentes importantes de atividades cerebrais, que estão dispostas abaixo dos 100 Hz.
Ao sinal de saída do filtro RC, novamente é aplicado um filtro passa-alta ativo de 0,72 Hz com um ganho fixo de 61x, onde o objetivo outra vez é cortar componentes de muito baixa frequência presentes no sistema.
Por último, é aplicado outro filtro passa-baixa passivo RC de 48,2 Hz, dessa vez com objetivo de atenuar principalmente o ruído de linha de 60 Hz.<br>
  O circuito completo possui um alto ganho, justificável pela baixa amplitude presente nos sinais de EEG (≅20 microvolts), que varia de 9.150 à 36.600 vezes. A banda de frequências que passa pelo circuito sem ser atenuada, está entre 0,72 Hz e 48,2 Hz. Para que a atividade elétrica cerebral seja posteriormente analisada em um notebook, a saída do circuito analógico é acoplada com uma entrada analógica 0 de um Arduino Uno, para que o microcontrolador Atmega328 converta o sinal de analógico para digital, em seguida enviando os dados para o notebook pela porta serial. No código embarcado no Arduino é empregado um delay de 5 ms, para que assim o sinal seja amostrado com uma frequência de 200 Hz.<br>

 #### B. Aquisição de dados

  A experiência foi desenvolvida a fim de verificar e validar a performance do sistema em modo offline, onde apenas são coletados dados para treinamento e teste, para que posteriormente o modelo de Machine Learning seja utilizado como classificador, em um outro experimento online que não faz parte desse presente trabalho.<br>
  Dois voluntários saudáveis, que não apresentam nenhum problema visual participaram deste estudo (2 homens com idades de 24 e 25 anos). Para dar início aos testes, os indivíduos sentaram em uma cadeira, a uma distância de aproximadamente 50 cm de um tela LCD, onde eram exibidos estímulos visuais. Essa estratégia é um procedimento padrão que é empregado em diversos estudos, quando se trata de paradigmas de Potenciais Evocados Visuais . O procedimento de aquisição de dados foi dividido entre dois grupos, em que cada um deles continha duas categorias a serem classificadas. As classes “Olho aberto” e “Olho fechado” fazem parte do grupo 1, enquanto “Estímulo 10 Hz” e “Estímulo 15 Hz” fazem parte do grupo 2. Para cada classe, foram performados 5 ensaios, cada um com 1 minuto de duração e com 3 minutos de descanso entre eles. Para os experimentos envolvendo o paradigma SSVEP (grupo 2), foi desenvolvido em Python uma interface gráfica de usuário (GUI), com a biblioteca “pygame”, onde nela eram mostrados dois quadrados piscantes, o primeiro com uma frequência de 10 Hz e o segundo com uma frequência de 15Hz.<br>
  Para treinamento e teste, a aquisição dos dados foi feita utilizando o software open-source “Spike Recorder”, desenvolvido pela a equipe Backyard Brains. Esse software apresenta um conjunto de filtros digitais, que podem ser aplicados ao sinal. Quando a opção “Record” é selecionada, os dados são gravados com uma taxa de 10.000 amostras por segundo, sendo armazenados num arquivo “.WAV”.<br>


 #### C. Pré-processamento, Extração de Características e Classificação

  A seguir são listadas as metodologias abordadas para o tratamento e classificação dos dados, que foram registrados em cada um dos grupo, e classes submetidas aos ensaios. Para esse processo foi utilizada a ferramenta [“Jupyter Notebook”](https://github.com/maods2/TCC-My-Brain-Computer-Interface/blob/master/Notebook%205.0%20-%20Eyes%20Closed%20Dataset.ipynb), que é um ambiente de programação que traz consigo a ideia de caderno de notas, muito utilizado em projetos de Data Science.<br>
  1) Pré-processamento: Após aquisição dos dados, cada classe foi importada e armazenada no ambiente de programação do Jupyter Notebook. Para cada classe foram criados 10 vetores, cada um referente a um minuto de sinal EEG. Devido às características intrínsecas de sinais EEG, com o propósito de não perder nenhuma informação importante no momento de segmentação dos dados, foi aplicada uma janela deslizante  sobre os vetores das classes, para formar uma única matriz, onde cada linha correspondia a uma janela de um 1 segundo, com 10.000 pontos amostrados. Para finalizar essa primeira etapa, em cada grupo, as classes foram empilhadas numa mesma matriz e então foi criada uma nova coluna para armazenar a classificação de cada classe: “0” para “Olho aberto” / “Estímulo 10 Hz” e “1” para “Olho fechado” / “Estímulo 15 Hz”. Foi arbitrado a utilização “0”s e “1”s na coluna de valores alvo, pois alguns modelos de Machine Learning trazidos nesse experimento, apenas funcionam com dados quantitativos.<br>
Uma vez criada a matriz com dados EEG, foi feito um “resample” nos sinais, diminuindo a frequência de amostragem de 10.000 para 200 amostras por segundo, já que pelo teorema de amostragem de nyquist, a frequência de amostragem de um sinal tem que ser pelo menos duas vezes o valor da maior frequência desejada no mesmo. Após esse procedimento, A matriz foi normalizada, para evitar problemas de classificação posteriores, devido a possiveis mudança de amplitude do sinal registrado, em decorrência de alguns fatores inerentes ao circuito de amplificação, como por exemplo o descarregamento gradual das pilhas que alimentam o circuito.<br>
  2) Extração de Características: No processo de extração de características foram exploradas quatro estratégias.
A primeira estratégia se baseia na análise de sinais no domínio da frequência, com a pequena ressalva da aplicação da Transformada de Fourier em janelas curtas de tempo, o que se assemelha com o algoritmo da Transformada rápida de Fourier. O procedimento basicamente se resumia em aplicar o algoritmo FFT a cada linha da matriz de EEG. Desta maneira, todo vetor resultante das FFTs (linhas da nova matriz de característica) era considerado como entradas nos respectivos modelos de Machine Learning.<br>
O segundo esquema adotado compartilhava do mesmo princípio da análise no domínio da frequência, porém como uma diferença. Após a execução e criação da matriz de FFTs, mais um recurso de extração de características foi empregado, onde alguns parâmetros estatísticos (Frequência dos três maiores picos, Amplitudes dos três maiores picos, Entropia Espectral, Centroide Espectral, Spectral RollOff) eram extraídos do espectro de Fourier, eventualmente formando uma nova matriz de características, que seria utilizada como nova entrada para os modelos.<br>
A metodologia de extração de características subseguiste faz o uso da Transformada de Wavelet Discreta. Para esse experimento, os sinais de EEG contidos na matriz normalizada são submetidos à uma decomposição de Wavelet com 2 níveis, onde o último nível apresenta a sub-banda, em que as frequências desejadas para análise do EEG estão presentes. Posteriormente, alguns outros parâmetros estatísticos (Zero Crossing Rate, Energia do Sinal, Entropia da Energia, entre outros), para sinais no domínio do tempo, são extraídos da forma de onda resultante da Transformada Discreta de Wavelet. A partir dessa lista de parâmetros, são selecionados dois conjuntos de características, definidos por dois algoritmos de seleção de características (correlação de Pearson e feature importance-RandomForest), uma coleção para a terceira estratégia e mais outra coleção para quarta estratégia de extração.<br>
  3) Classificação: Para o processo de classificação, foram utilizados os modelos “k-Nearest Neighbor”, “Naive Bayes”, “Multilayer Perceptron” , “Linear Discriminant Analysis” e “Suport Vector Machine”, que se mostram os algoritmos de melhor performance neste tipo de aplicação.<br>
Para iniciar o processo de treinamento dos modelos, a matriz de características de cada grupamento de datasets diferentes, são divididas entre dados de treinamento e dados de teste, sendo respectivamente 80% e 20% dos dados destinados para cada função. Para validação dos modelos é utilizada a técnica de “Cross-Validation”, que nada mais é que um método de validação cruzada onde é investigada a eficiência de generalização de um modelo em relação a um conjunto de dados. A partir daí são comparados os resultados de performance dos modelos.<br>

### 3. CONTEÚDO DO REPOSITÓRIO
O projeto da Interface cérebro-Computador ainda está em andamento, porém nesse repositório é possivel encontrar o modelo de notebook que foi usado para explorar, pré-processar e treinar os modelos. Além disso, está presente o código de uma GUI que está sendo desenvolvida para mostrar em tempo real a onda capitada em tempo real e tambem a sua classificação.
